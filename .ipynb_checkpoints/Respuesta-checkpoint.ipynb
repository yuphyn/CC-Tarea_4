{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"escudo_utfsm.gif\" style=\"float:right;height:100px\">\n",
    "<img src=\"IsotipoDIisocolor.png\" style=\"float:left;height:100px\">\n",
    "<center>\n",
    "    <h1> ILI285 - Computación Científica I / INF285 - Computación Científica</h1>\n",
    "    <h1> Tarea 4: PageRank y GMRes </h1>\n",
    "    <h2> César Quiroz Mansilla </h2>\n",
    "    <h2> 201573578-6 </h2>\n",
    "    <h2> cesar.quirozm@sansano.usm.cl </h2>\n",
    "    <h3> [S]cientific [C]omputing [T]eam 2019</h3>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy as sp\n",
    "from time import time\n",
    "from ipywidgets import interact, IntSlider\n",
    "#if not instaled: pip3 install networkx\n",
    "import networkx as nx\n",
    "from scipy.sparse.linalg import gmres\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank\n",
    "\n",
    "Para poder trabajar con el algoritmo, es necesario considerar inicialmente una matriz de adyacencia $A \\in \\mathbb{R}^{n \\times n}$, con $n$ la cantidad de páginas web. Las entradas $a_{ij}$ de esta matriz tienen el valor 1 si la página $i$ tiene un enlace a la página $j$ y 0 en caso contrario. Notar que no necesariamente la matriz $A$ es simétrica, lo que denota que dos páginas web distintas podrían no enlazarse mutuamente. Además, considere que una misma página no se enlazará consigo misma, por lo que la matriz tendrá cero en su diagonal principal. \n",
    "\n",
    "Adicionalmente, podrían darse casos de que existan páginas que solo tienen links hacia ellas, pero no tienen links hacia otras páginas. En una representación de la matriz de adyacencia como grafo, se le conoce a estas páginas como nodos _sumideros_. Una consecuencia de estos casos podía ser que usuarios que llegan a esas páginas quedan retenidos porque no existen links a los cuales seguir navegando. Para evitar esta situación, se agregará la perturbación _rank-one_ a la matriz de adyacencia $A$.\n",
    "\n",
    "$$\n",
    "    \\tilde{A} = A + \\mathbf{a}\\cdot\\mathbf{1}^T,\n",
    "$$\n",
    "\n",
    "donde $\\mathbf{a} \\in \\mathbb{R}^{n}$ es un vector con un $1$ en la componente que corresponde a los nodos sumideros  y $0$ en los otras componentes, el vector $\\mathbf{1}$ corresponde al vector de unos en $\\mathbb{R}^{n}$ y $^T$ es el operador transpuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "Considere los datasets de los archivos `adjacency1.dat`, `adjacency2.dat`, `adjacency3.dat` y `adjacency4.dat`, que representan matrices de adyacencia tales que:\n",
    "- Adjacency1 es una matriz de adyacencia de 100 páginas y alrededor de un 20% de elementos no nulos.\n",
    "- Adjacency2 es una matriz de adyacencia de 100 páginas y alrededor de un 50% de elementos no nulos.\n",
    "- Adjacency3 es una matriz de adyacencia de 100 páginas y alrededor de un 80% de elementos no nulos.\n",
    "- Adjacency4 es una matriz de adyacencia de 1000 páginas y alrededor de un 5% de elementos no nulos.\n",
    "\n",
    "Cada fila $i$ de un archivo dataset corresponde a una página de índice $i$, y todos los valores separados por espacios en dicha fila representan los índices de las páginas $j$ a las cuales $i$ apunta. En otras palabras, un archivo dataset registra los vértices del grafo de adyacencia.\n",
    "\n",
    "Considere la siguiente función,`read_adjacency_matrix` , que obtiene la matriz de adyacencia a partir de los archivos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input:\n",
    "filename - (string) name of adjacency matrix file\n",
    "Output: \n",
    "A - (n x n matrix) adjacency matrix\n",
    "'''\n",
    "def read_adjacency_matrix(file_path):\n",
    "    adjacency_list = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            adjacency_list.append(np.array(list(map(int, line.split()))))\n",
    "    n = len(adjacency_list)\n",
    "    A = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        A[i, adjacency_list[i]] = 1\n",
    "    return A\n",
    "A = read_adjacency_matrix(\"adjacency1.dat\")\n",
    "B = read_adjacency_matrix(\"adjacency2.dat\")\n",
    "C = read_adjacency_matrix(\"adjacency3.dat\")\n",
    "D = read_adjacency_matrix(\"adjacency4.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 1 : Comparación de soluciones con GMRes y PALU\n",
    "\n",
    "En esta sección se compararán las soluciones de PageRank obtenidas por medio de GMRes y PALU. Para esto, se considerarán los datasets de los archivos `adjacency1.dat`, `adjacency2.dat`, `adjacency3.dat` y `adjacency4.dat`, variaciones en el _damping factor_ $\\alpha$ y el número de iteraciones $k$ de GMRes.\n",
    "\n",
    "**1.** Construya el sistema lineal necesario para encontrar PageRank. Para ello desarrolle la función `build_linear_system`, que recibe una matriz de adyacencia $A$ y un _damping factor_ $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input:\n",
    "A - (n x n matrix) adjacency matrix\n",
    "alpha - (float) damping factor, takes values from 0 to 1\n",
    "Output: \n",
    "A_hat - (n x n matrix) matrix of linear system\n",
    "b_hat - (n vector) right hand side vector of linear system\n",
    "'''\n",
    "def build_linear_system(A, alpha):\n",
    "    #matriz P \n",
    "    P = np.zeros((len(A),len(A)))\n",
    "    P=A\n",
    "    v1=0\n",
    "    for x in P:\n",
    "        v2=0\n",
    "        s=sum(x)\n",
    "        for i in x:\n",
    "            if i==1:\n",
    "                P[v1][v2]=1/s\n",
    "            v2=v2+1\n",
    "        v1=v1+1\n",
    "    #matriz I\n",
    "    I=np.zeros((len(A),len(A)))\n",
    "    np.fill_diagonal(I,1)\n",
    "    #Matriz v\n",
    "    v=np.full((len(A), 1), 1/len(A))\n",
    "    #b_hat\n",
    "    b_hat=np.zeros((len(A),len(A)))\n",
    "    b_hat=(1-alpha)*v\n",
    "    #A_hat\n",
    "    A_hat=np.zeros((len(A),len(A)))\n",
    "    A_hat=I-(alpha*np.transpose(P))               \n",
    "    return A_hat, b_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Considere el error $e_k = \\|\\mathbf{x^{k}_{G}}-\\mathbf{x_{P}}\\|_2$ una métrica de error que compara $\\mathbf{x_{P}}$, la solución de PageRank obtenida por PALU, con $\\mathbf{x^{k}_{G}}$ la solución de PageRank obtenida con $k$ iteraciones de GMRes. Construya un gráfico que muestre $e_k$ versus $k$ y utilice un widget para seleccionar un dataset y variar el valor del _damping factor_ $\\alpha$. ¿Qué puede decir de la información mostrada en el gráfico? ¿Cómo afecta $\\alpha$ en los resultados obtenidos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "###PALU\n",
    "#  Resuelve \n",
    "def solve_triangular(A, b, upper=True):\n",
    "    n = b.shape[0]\n",
    "    x = np.zeros_like(b)\n",
    "    if upper==True:\n",
    "        #perform back-substitution\n",
    "        x[-1] = (1./A[-1,-1]) * b[-1]\n",
    "        for i in range(n-2, -1, -1):\n",
    "            x[i] = (1./A[i,i]) * (b[i] - np.sum(A[i,i+1:] * x[i+1:]))\n",
    "    else:\n",
    "        #perform forward-substitution\n",
    "        x[0] = (1./A[0,0]) * b[0]\n",
    "        for i in range(1,n):\n",
    "            x[i] = (1./A[i,i]) * (b[i] - np.sum(A[i,:i] * x[:i]))\n",
    "    return x\n",
    "#Descompone matriz en matrices PA=LU\n",
    "def palu_decomp(A):\n",
    "    N,_ = A.shape\n",
    "    P = np.identity(N)\n",
    "    L = np.zeros((N,N))\n",
    "    U = np.copy(A)\n",
    "    #iterating through columns\n",
    "    for j in range(N-1):\n",
    "        #determine the new pivot\n",
    "        p_index = np.argmax(np.abs(U[j:,j]))\n",
    "        if p_index != 0:\n",
    "            row_perm(P, j, j+p_index)\n",
    "            row_perm(U, j, j+p_index)\n",
    "            row_perm(L, j, j+p_index)\n",
    "        #iterating through rows\n",
    "        for i in range(j+1,N):\n",
    "            L[i,j] = U[i,j]/U[j,j]\n",
    "            U[i] -= L[i,j]*U[j]\n",
    "    np.fill_diagonal(L,1)\n",
    "    return P,L,U\n",
    "#Resuelve Matriz PALU\n",
    "def solve_palu(A, b):\n",
    "    P,L,U = palu_decomp(A)\n",
    "    #A.x = b -> P.A.x = P.b = b'\n",
    "    b = np.dot(P,b)\n",
    "    # L.c = b' with c = U.x\n",
    "    c = solve_triangular(L, b, upper=False)\n",
    "    x = solve_triangular(U, c)\n",
    "    x=(1/sum(x))*x\n",
    "    return x\n",
    "\n",
    "##GMres\n",
    "# Funcion Metodo minimo residuos generalizados\n",
    "def GMRes(A, b, x0=np.array([0.0]), m=10, flag_display=False, threshold=1e-12):\n",
    "    todas=np.zeros((m,len(b)))\n",
    "    n = len(b)\n",
    "    if len(x0)==1:\n",
    "        x0=np.zeros(n)\n",
    "    r0 = b - np.dot(A, x0)\n",
    "    nr0=np.linalg.norm(r0)\n",
    "    out_res=np.array(nr0)\n",
    "    Q = np.zeros((n,n))\n",
    "    H = np.zeros((n,n))\n",
    "    Q[:,0] = r0 / nr0\n",
    "    flag_break=False\n",
    "    matris=0\n",
    "    for k in np.arange(np.min((m,n))):\n",
    "        y = np.dot(A, Q[:,k])\n",
    "        if flag_display:\n",
    "            print('||y||=',np.linalg.norm(y))\n",
    "        for j in np.arange(k+1):\n",
    "            H[j][k] = np.dot(Q[:,j], y)\n",
    "            if flag_display:\n",
    "                print('H[',j,'][',k,']=',H[j][k])\n",
    "            y = y - np.dot(H[j][k],Q[:,j])\n",
    "            if flag_display:\n",
    "                print('||y||=',np.linalg.norm(y))\n",
    "        # All but the last equation are treated equally. Why?\n",
    "        if k+1<n:\n",
    "            H[k+1][k] = np.linalg.norm(y)\n",
    "            if flag_display:\n",
    "                print('H[',k+1,'][',k,']=',H[k+1][k])\n",
    "            if (np.abs(H[k+1][k]) > 1e-16):\n",
    "                Q[:,k+1] = y/H[k+1][k]\n",
    "            else:\n",
    "                #print('flag_break has been activated')\n",
    "                flag_break=True\n",
    "            # Do you remember e_1? The canonical vector.\n",
    "            e1 = np.zeros((k+1)+1)        \n",
    "            e1[0]=1\n",
    "            H_tilde=H[0:(k+1)+1,0:k+1]\n",
    "        else:\n",
    "            H_tilde=H[0:k+1,0:k+1]\n",
    "        # Solving the 'SMALL' least square problem. \n",
    "        # This could be improved with Givens rotations!\n",
    "        ck = np.linalg.lstsq(H_tilde, nr0*e1)[0] \n",
    "        if k+1<n:\n",
    "            x = x0 + np.dot(Q[:,0:(k+1)], ck)\n",
    "        else:\n",
    "            x = x0 + np.dot(Q, ck)\n",
    "        # Why is 'norm_small' equal to 'norm_full'?\n",
    "        norm_small=np.linalg.norm(np.dot(H_tilde,ck)-nr0*e1)\n",
    "        out_res = np.append(out_res,norm_small)\n",
    "        if flag_display:\n",
    "            norm_full=np.linalg.norm(b-np.dot(A,x))\n",
    "            #print('..........||b-A\\,x_k||=',norm_full)\n",
    "            #print('..........||H_k\\,c_k-nr0*e1||',norm_small);\n",
    "        todas[matris]=x\n",
    "        matris=matris+1\n",
    "        #print(x)\n",
    "        if flag_break:\n",
    "            if flag_display: \n",
    "                print('EXIT: flag_break=True')\n",
    "            break\n",
    "        if norm_small<threshold:\n",
    "            if flag_display:\n",
    "                print('EXIT: norm_small<threshold')\n",
    "            break\n",
    "    return todas,out_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc04a6bff3a24e14918eb5f0443c6444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='data', max=4, min=1), FloatSlider(value=0.55, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.error(data, alpha, k)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtiene error implicado y genera gráfico plot vs error \n",
    "def error(data,alpha,k):\n",
    "    errores=[]\n",
    "    if data==1:\n",
    "        Ma,Vb=build_linear_system(A,alpha)\n",
    "    elif data==2:\n",
    "        Ma,Vb=build_linear_system(B,alpha)\n",
    "    elif data==3:\n",
    "        Ma,Vb=build_linear_system(C,alpha)\n",
    "    else:\n",
    "        Ma,Vb=build_linear_system(D,alpha)\n",
    "    Px=solve_palu(Ma,Vb)   \n",
    "    Vb=np.transpose(Vb)\n",
    "    Gxk, _ = GMRes(Ma, Vb[0],m=k)\n",
    "    for x in Gxk:\n",
    "        con=0\n",
    "        Gx=np.zeros((len(x),1))\n",
    "        for i in x:\n",
    "            Gx[con]=i\n",
    "            con=con+1\n",
    "        err=np.linalg.norm(Gx-Px)\n",
    "        errores.append(err)\n",
    "    lista = range(1,len(errores)+1)\n",
    "    vx=list(lista)\n",
    "    plt.scatter(vx, errores)\n",
    "    #plt.ylim(0.4, 0.48)\n",
    "    plt.xlabel('K iteration')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title(\"Plot k v/s error\")\n",
    "    plt.show()\n",
    "    return 0\n",
    "\n",
    "interact(error,data=IntSlider(min=1,max=4,step=1,value=3),alpha=(0.1,1.0,0.01),k=IntSlider(min=1,max=200,step=1,value=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico se observa que al cambiar las K itteraciones el error encontrado se mantiene constante, es decir que GMres ya encontro la mejor respusta y cada vector x mantiene los mismos valores, por otro lado, al cambiar el valor de alpha se obtiene que:\n",
    " \n",
    " + con valores más bajo el error disminuye.\n",
    " \n",
    " + con valores altos el error va aumentando.\n",
    " \n",
    "eso implica que dependiendo el peso que se le da a la matriz  random jump y matriz de de pesos, los modelos PALU y GMres van obteniendo resultados distintos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 2 : Tiempo de Ejecución\n",
    "\n",
    "En esta sección se compararán los tiempos de ejecución de GMRes y PALU necesarios para resolver los sistemas de ecuaciones de PageRank. Para esto, se considerarán los datasets de los archivos `adjacency1.dat`, `adjacency2.dat`, `adjacency3.dat` y `adjacency4.dat`, variaciones en el _damping factor_ $\\alpha$ y el número de iteraciones $k$ de GMRes.\n",
    "\n",
    "**1.** Analice efecto de variar _damping factor_ $\\alpha$ para encontrar las 10 primeras páginas entregadas por PageRank. Para ello utilice la función `get_damping_ranking` definida a continuación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cesar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.40000000e+01, 1.25840274e-02]),\n",
       " array([3.70000000e+01, 1.19785908e-02]),\n",
       " array([7.40000000e+01, 1.19208987e-02]),\n",
       " array([6.00000000e+01, 1.16476491e-02]),\n",
       " array([5.00000000e+01, 1.15140201e-02]),\n",
       " array([9.60000000e+01, 1.15052893e-02]),\n",
       " array([3.40000000e+01, 1.13483387e-02]),\n",
       " array([1.        , 0.01130623]),\n",
       " array([6.80000000e+01, 1.13008833e-02]),\n",
       " array([8.90000000e+01, 1.12636799e-02])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OBtiene las 10 primeras paginas de PageRank\n",
    "def top(lista):\n",
    "    list_top=[]\n",
    "    n = lista\n",
    "    idx = n.argsort()[-1]\n",
    "    list_top.append(np.array((idx+1, n[idx])))\n",
    "    idx2 = n.argsort()[-2]\n",
    "    list_top.append(np.array((idx2+1, n[idx2])))\n",
    "    idx3 = n.argsort()[-3]\n",
    "    list_top.append(np.array((idx3+1, n[idx3])))\n",
    "    idx4 = n.argsort()[-4]\n",
    "    list_top.append(np.array((idx4+1, n[idx4])))\n",
    "    idx5 = n.argsort()[-5]\n",
    "    list_top.append(np.array((idx5+1, n[idx5])))\n",
    "    idx6 = n.argsort()[-6]\n",
    "    list_top.append(np.array((idx6+1, n[idx6])))\n",
    "    idx7 = n.argsort()[-7]\n",
    "    list_top.append(np.array((idx7+1, n[idx7])))\n",
    "    idx8 = n.argsort()[-8]\n",
    "    list_top.append(np.array((idx8+1, n[idx8])))\n",
    "    idx9 = n.argsort()[-9]\n",
    "    list_top.append(np.array((idx9+1, n[idx9])))\n",
    "    idx10 = n.argsort()[-10]\n",
    "    list_top.append(np.array((idx10+1, n[idx10])))    \n",
    "    return list_top\n",
    "        \n",
    "'''\n",
    "Input:\n",
    "A - (n x n matrix) adjacency matrix\n",
    "alpha - (float) damping factor, takes values from 0 to 1\n",
    "k - number of iterations of GMRes until return a solution, use only if method is 'GMRes'\n",
    "method - string that indicates the method used to solve the linear system. Take values 'PALU' or 'GMRes'\n",
    "Output: \n",
    "ranking - list with 10 pages of ranking sorted by largest probability\n",
    "'''\n",
    "#Obtiene el damping ranking \n",
    "def get_damping_ranking(A, alpha, k, method='GMRes'):\n",
    "    Ma,Vb=build_linear_system(A, alpha)\n",
    "    Px=solve_palu(Ma,Vb)   \n",
    "    Vb=np.transpose(Vb)       \n",
    "    if \"GMRes\"== method:\n",
    "        Gxk, _ = GMRes(Ma, Vb[0],m=k)\n",
    "        Gx=np.zeros((len(Ma),1))\n",
    "        Gx=Gxk[len(Gxk)-1]\n",
    "        ranking=top(Gx)\n",
    "        \n",
    "    else:\n",
    "        Px=np.transpose(Px)[0]\n",
    "        ranking=top(Px)\n",
    "    return ranking\n",
    "\n",
    "\n",
    "get_damping_ranking(A,0.5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Construya un gráfico que muestre el tiempo de ejecución para determinar el ranking versus el factor de amortiguamiento $\\alpha$. En el mismo gráfico debe mostrar los dos métodos utilizados (GMRes y PALU). Además, utilice un widget que permita seleccionar uno de los cuatro datasets mencionados y el número $k$ de iteraciones de GMRes. ¿Qué puede decir respecto de los resultados obtenidos en cada método al variar el valor de $\\alpha$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38dd4ba59d5d4b3c85c304b42547e327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='data', max=4, min=1), IntSlider(value=10, description='k…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.tiempo(data, k, metodo)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#metodo=1 GMRes\n",
    "#metodo=2 PALU\n",
    "#Obtiene los tiempos de ejecucion de cada dato\n",
    "def tiempo (data,k,metodo):\n",
    "    alpha=0\n",
    "    lista_1=[]\n",
    "    lista_2=[]\n",
    "    if data==1:\n",
    "        dA = read_adjacency_matrix(\"adjacency1.dat\")\n",
    "    elif data==2:\n",
    "        dA = read_adjacency_matrix(\"adjacency2.dat\")\n",
    "    elif data==3:\n",
    "        dA = read_adjacency_matrix(\"adjacency3.dat\")\n",
    "    else:\n",
    "        dA = read_adjacency_matrix(\"adjacency4.dat\")\n",
    "    for i in range(1,20):        \n",
    "        tiempo_inicial = time() \n",
    "        if metodo==1:\n",
    "            get_damping_ranking(dA, alpha, k, method='GMRes')\n",
    "        else:\n",
    "            get_damping_ranking(dA, alpha, k, method='PALU')\n",
    "\n",
    "        lista_1.append(alpha)\n",
    "        alpha=alpha+0.05\n",
    "        tiempo_final = time() \n",
    "        tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "        lista_2.append(tiempo_ejecucion)\n",
    "    plt.scatter(lista_2, lista_1)\n",
    "    plt.title(\"alpha vs tiempo\")\n",
    "    plt.xlabel('Tiempo Ejecución')\n",
    "    plt.ylabel('Valor Alpha')\n",
    "    plt.show()\n",
    "    return 0\n",
    "\n",
    "#tiempo(4,A,B,C,D,10,1)\n",
    "\n",
    "interact(tiempo,data=IntSlider(min=1,max=4,step=1,value=3),k=IntSlider(min=1,max=100,step=1,value=10),metodo=(1,2,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa en el grafico, el tiempo de computacion no depende de el valor alpha, tanto para el metodo 1 yb 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 3 : Análisis de iteraciones de GMRes\n",
    "\n",
    "En esta sección debe analizar las soluciones obtenidas por GMRes en cada iteración, utilizando los datasets `web-NotreDame` y `web-Stanford`. Se recomienda modificar el código de GMRes de los Jupyter Notebook del curso, aunque no es obligatorio. **Importante:** Debido al tamaño de estos datasets, no se debe intentar cargar toda la matriz de adyacencia en memoria en formato denso\n",
    "\n",
    "Considere la relación error $e_{k}$ versus iteración $k$, donde el error puede ser definido de la siguiente manera:\n",
    "\n",
    "$$\n",
    "e_{k} = \\| \\mathbf{x}_{k}-\\mathbf{x}_{k-1} \\|_2\n",
    "$$\n",
    "\n",
    "   Donde $\\mathbf{x}_k$ es la solución de GMRes obtenida en la iteración $k$-ésima, con $k$ que **puede tomar valores** en el rango $[1, 2, \\ldots, m]$. y $m$ el número de páginas del dataset. \n",
    "   \n",
    "**1.** Utilice GMRes de manera conveniente para graficar el error $e_k$ versus $k$, utilizando un widget para variar el _damping factor_ $\\alpha$ y seleccionar uno de los dos datasets requeridos. ¿Qué puede decir del error a medida que $k$ aumenta? ¿En qué afecta el valor de $\\alpha$?\n",
    "\n",
    "**Recomendación:** no intente cargar toda la matriz $\\widehat{A}$ en memoria. En lugar de eso, considere que debido a que $\\widehat{A}$ es _sparse_, la matriz $P$ también lo es y evite el cálculo de productos exteriores explícitamente. Se recomienda revisar el módulo `sparse` de `scipy` . Puede recurrir a modificaciones de GMRes para desarrollar esta pregunta. Utilice un valor máximo de $k$ razonable, pero no muy pequeño. No debe llegar necesariamente a $k = m$. Justifique su elección apropiadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281904, 281904)\n",
      "(325729, 325729)\n"
     ]
    }
   ],
   "source": [
    "#Crear las matices para cada dataset\n",
    "def crear_matriz(file_path):\n",
    "    data=[]\n",
    "    row_ind=[]\n",
    "    col_ind=[]\n",
    "    diagonal=[]\n",
    "    cantidad=0\n",
    "    row=[]\n",
    "    col=[]\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line[0] !=\"#\":\n",
    "                data.append(1)\n",
    "                row_ind.append(int(line.split(\"\\t\" )[0]))\n",
    "                col_ind.append(int(line.split(\"\\t\" )[1]))\n",
    "     \n",
    "    x=sparse.csr_matrix ((data, (row_ind, col_ind))) \n",
    "    print(x.shape)\n",
    "    cantidad=x.shape[0]\n",
    "    for i in range(cantidad):\n",
    "        row.append(i)\n",
    "        col.append(i)\n",
    "        diagonal.append(1)    \n",
    "    y=sparse.csr_matrix ((diagonal, (row, col)))\n",
    "    return x,y,cantidad\n",
    "\n",
    "MA,MI1,can1=crear_matriz(\"web-Stanford.txt\")\n",
    "MB,MI2,can2=crear_matriz(\"web-NotreDame.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función anterior entrega como resultado 3 varoables:\n",
    "\n",
    "* Matriz sparse completa\n",
    "\n",
    "* Matriz diagonal Sparse\n",
    "\n",
    "* Dimension n de la matriz nxn\n",
    "\n",
    "Con esto se pasa a calcular la matriz P y v ( Tal como se realiza en la pregunta 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MA1= [((i, j), MA[i,j]) for i, j in zip(*MA.nonzero())]\n",
    "MB1= [((i, j), MB[i,j]) for i, j in zip(*MB.nonzero())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion matriz P \n",
    "def matriz_p(A,can):\n",
    "    v=np.full((can, 1), 1/can)\n",
    "    mv=sparse.csr_matrix (v)\n",
    "    l=[]\n",
    "    c=0\n",
    "    j=0\n",
    "    z=0\n",
    "    for i in A:\n",
    "        if i[0][0]==c:\n",
    "            j=j+1\n",
    "        else:\n",
    "            l.append(j)\n",
    "            j=1\n",
    "            c=c+1\n",
    "    if l[0]==0:\n",
    "        l.pop(0)\n",
    "    data=[]\n",
    "    row=[]\n",
    "    col=[]\n",
    "    c=0\n",
    "    j=l[0]\n",
    "    b=0\n",
    "    for i in A:\n",
    "        if j>0:\n",
    "            data.append(1/l[c])\n",
    "            row.append(i[0][0])\n",
    "            col.append(i[0][1])\n",
    "            j=j-1\n",
    "        elif j==0:\n",
    "            c=c+1\n",
    "            j=l[c]\n",
    "            data.append(1/l[c])\n",
    "            row.append(i[0][0])\n",
    "            col.append(i[0][1])\n",
    "    x=sparse.csr_matrix ((data, (row, col)))\n",
    "    \n",
    "    return x,mv\n",
    "    \n",
    "P1,V1=matriz_p(MA1,can1)\n",
    "P2,V2=matriz_p(MB1,can2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funcion anterior Calcula la matriz P y V y con ellos se tiene todo lo necesario para encontrar la matriz $\\widehat{A}$ y la matriz y $\\widehat{\\mathbf{b}} $.\n",
    "\n",
    "Para encotrar $\\widehat{A}$ y $\\widehat{b}$ se crea la función \"build_linear_system_v2\" que es una nueva versión de la funcón creada en la primera parte de este trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281904, 281904)\n",
      "(281904, 281904)\n"
     ]
    }
   ],
   "source": [
    "#Sistema lineal\n",
    "def build_linear_system_v2(alpha,I,V,P):\n",
    "    #b_hat\n",
    "    b_hat=(1-alpha)*V\n",
    "    #A_hat\n",
    "    A_hat=I-(alpha*P.T)               \n",
    "    return A_hat, b_hat\n",
    "ah,bh=build_linear_system_v2(0.5,MI1,V1,P1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finnalmente se modifica la funcón GMres sacada del jupyter del curso, para que funcióne con matrices sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-3c7cc5f54646>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtodas\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout_res\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m \u001b[0mGMRes_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mah\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-76-3c7cc5f54646>\u001b[0m in \u001b[0;36mGMRes_v2\u001b[1;34m(A, b, x0, m, flag_display, threshold)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mQ\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mQ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnr0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mflag_break\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mmatris\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36mtodense\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    844\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mshares\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m         \"\"\"\n\u001b[1;32m--> 846\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    945\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##GMres\n",
    "# Funcion Metodo minimo residuos generalizados\n",
    "def GMRes_v2(A, b, x0=np.array([0.0]), m=1, flag_display=False, threshold=1e-12):\n",
    "    todas=np.zeros((m,b.shape[0]))\n",
    "    n = b.shape[0]\n",
    "    if len(x0)==1:\n",
    "        x0=np.zeros(n)\n",
    "        #print(A.shape)\n",
    "        #print(x0.shape)\n",
    "        x0=sparse.csr_matrix(x0).T\n",
    "        #print(x0.shape)\n",
    "    r0 = b - (A*x0)\n",
    "    r0=r0.todense()\n",
    "    nr0=np.linalg.norm(r0)\n",
    "    out_res=np.array(nr0)\n",
    "    Q =sparse.csr_matrix ((n, n), )\n",
    "    H =sparse.csr_matrix ((n, n), )\n",
    "    Q.todense()[:,0] = r0 / nr0\n",
    "    flag_break=False\n",
    "    matris=0\n",
    "    for k in np.arange(np.min((m,n))):\n",
    "        y= A*sparse.csr_matrix(Q[:,k])\n",
    "        y=y.todense()\n",
    "        data=[]\n",
    "        row=[]\n",
    "        col=[]\n",
    "        #y = np.dot(A, Q[:,k])\n",
    "        if flag_display:\n",
    "            print('||y||=',np.linalg.norm(y))\n",
    "        for j in np.arange(k+1):\n",
    "            row.append(j)\n",
    "            col.append(k)\n",
    "            print(np.dot(Q[:,j], y))\n",
    "            data.append(np.dot(Q[:,j], y))\n",
    "            H[j][k] = np.dot(Q[:,j], y)\n",
    "            if flag_display:\n",
    "                print('H[',j,'][',k,']=',H[j][k])\n",
    "            y = y - np.dot(H[j][k],Q[:,j])\n",
    "            if flag_display:\n",
    "                print('||y||=',np.linalg.norm(y))\n",
    "        # All but the last equation are treated equally. Why?\n",
    "        if k+1<n:\n",
    "            H[k+1][k] = np.linalg.norm(y)\n",
    "            if flag_display:\n",
    "                print('H[',k+1,'][',k,']=',H[k+1][k])\n",
    "            if (np.abs(H[k+1][k]) > 1e-16):\n",
    "                Q[:,k+1] = y/H[k+1][k]\n",
    "            else:\n",
    "                #print('flag_break has been activated')\n",
    "                flag_break=True\n",
    "            # Do you remember e_1? The canonical vector.\n",
    "            e1 = np.zeros((k+1)+1)        \n",
    "            e1[0]=1\n",
    "            H_tilde=H[0:(k+1)+1,0:k+1]\n",
    "        else:\n",
    "            H_tilde=H[0:k+1,0:k+1]\n",
    "        # Solving the 'SMALL' least square problem. \n",
    "        # This could be improved with Givens rotations!\n",
    "        ck = np.linalg.lstsq(H_tilde, nr0*e1)[0] \n",
    "        if k+1<n:\n",
    "            x = x0 + np.dot(Q[:,0:(k+1)], ck)\n",
    "        else:\n",
    "            x = x0 + np.dot(Q, ck)\n",
    "        # Why is 'norm_small' equal to 'norm_full'?\n",
    "        norm_small=np.linalg.norm(np.dot(H_tilde,ck)-nr0*e1)\n",
    "        out_res = np.append(out_res,norm_small)\n",
    "        if flag_display:\n",
    "            norm_full=np.linalg.norm(b-np.dot(A,x))\n",
    "            #print('..........||b-A\\,x_k||=',norm_full)\n",
    "            #print('..........||H_k\\,c_k-nr0*e1||',norm_small);\n",
    "        todas[matris]=x\n",
    "        matris=matris+1\n",
    "        #print(x)\n",
    "        if flag_break:\n",
    "            if flag_display: \n",
    "                print('EXIT: flag_break=True')\n",
    "            break\n",
    "        if norm_small<threshold:\n",
    "            if flag_display:\n",
    "                print('EXIT: norm_small<threshold')\n",
    "            break\n",
    "    return todas,out_res\n",
    "\n",
    "GMRes_v2(ah,bh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 4 : Conclusiones\n",
    "\n",
    "Ya que GMres es un metodo iterativo para encontrar soluciones numericas, de sistemas de ecuaciones lineales no simetricos, por lon tanto la aproximación es conseguida mediante un sub espacio de krylov con residuos minimos.\n",
    "\n",
    "Por lo tanto tiene mayor facilidad en trabajar con matrices Sparse, lo cual es ideal para trabajar en problemas del tipo matriz Google."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias\n",
    "\n",
    "* Jupyter_Notebook_04_Metodos_Directos , del material de clases\n",
    "\n",
    "* https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.gmres.html\n",
    "\n",
    "* https://github.com/tclaudioe/Scientific-Computing/blob/master/SC1/10_GMRes.ipynb\n",
    "\n",
    "* https://machinelearningmastery.com/sparse-matrices-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
