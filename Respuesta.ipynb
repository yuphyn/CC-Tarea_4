{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"escudo_utfsm.gif\" style=\"float:right;height:100px\">\n",
    "<img src=\"IsotipoDIisocolor.png\" style=\"float:left;height:100px\">\n",
    "<center>\n",
    "    <h1> ILI285 - Computación Científica I / INF285 - Computación Científica</h1>\n",
    "    <h1> Tarea 4: PageRank y GMRes </h1>\n",
    "    <h2> César Quiroz Mansilla </h2>\n",
    "    <h2> 201573578-6 </h2>\n",
    "    <h2> cesar.quirozm@sansano.usm.cl </h2>\n",
    "    <h3> [S]cientific [C]omputing [T]eam 2019</h3>\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy as sp\n",
    "from time import time\n",
    "from ipywidgets import interact, IntSlider\n",
    "#if not instaled: pip3 install networkx\n",
    "import networkx as nx\n",
    "from scipy.sparse.linalg import gmres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank\n",
    "\n",
    "Para poder trabajar con el algoritmo, es necesario considerar inicialmente una matriz de adyacencia $A \\in \\mathbb{R}^{n \\times n}$, con $n$ la cantidad de páginas web. Las entradas $a_{ij}$ de esta matriz tienen el valor 1 si la página $i$ tiene un enlace a la página $j$ y 0 en caso contrario. Notar que no necesariamente la matriz $A$ es simétrica, lo que denota que dos páginas web distintas podrían no enlazarse mutuamente. Además, considere que una misma página no se enlazará consigo misma, por lo que la matriz tendrá cero en su diagonal principal. \n",
    "\n",
    "Adicionalmente, podrían darse casos de que existan páginas que solo tienen links hacia ellas, pero no tienen links hacia otras páginas. En una representación de la matriz de adyacencia como grafo, se le conoce a estas páginas como nodos _sumideros_. Una consecuencia de estos casos podía ser que usuarios que llegan a esas páginas quedan retenidos porque no existen links a los cuales seguir navegando. Para evitar esta situación, se agregará la perturbación _rank-one_ a la matriz de adyacencia $A$.\n",
    "\n",
    "$$\n",
    "    \\tilde{A} = A + \\mathbf{a}\\cdot\\mathbf{1}^T,\n",
    "$$\n",
    "\n",
    "donde $\\mathbf{a} \\in \\mathbb{R}^{n}$ es un vector con un $1$ en la componente que corresponde a los nodos sumideros  y $0$ en los otras componentes, el vector $\\mathbf{1}$ corresponde al vector de unos en $\\mathbb{R}^{n}$ y $^T$ es el operador transpuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "Considere los datasets de los archivos `adjacency1.dat`, `adjacency2.dat`, `adjacency3.dat` y `adjacency4.dat`, que representan matrices de adyacencia tales que:\n",
    "- Adjacency1 es una matriz de adyacencia de 100 páginas y alrededor de un 20% de elementos no nulos.\n",
    "- Adjacency2 es una matriz de adyacencia de 100 páginas y alrededor de un 50% de elementos no nulos.\n",
    "- Adjacency3 es una matriz de adyacencia de 100 páginas y alrededor de un 80% de elementos no nulos.\n",
    "- Adjacency4 es una matriz de adyacencia de 1000 páginas y alrededor de un 5% de elementos no nulos.\n",
    "\n",
    "Cada fila $i$ de un archivo dataset corresponde a una página de índice $i$, y todos los valores separados por espacios en dicha fila representan los índices de las páginas $j$ a las cuales $i$ apunta. En otras palabras, un archivo dataset registra los vértices del grafo de adyacencia.\n",
    "\n",
    "Considere la siguiente función,`read_adjacency_matrix` , que obtiene la matriz de adyacencia a partir de los archivos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input:\n",
    "filename - (string) name of adjacency matrix file\n",
    "Output: \n",
    "A - (n x n matrix) adjacency matrix\n",
    "'''\n",
    "def read_adjacency_matrix(file_path):\n",
    "    adjacency_list = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            adjacency_list.append(np.array(list(map(int, line.split()))))\n",
    "    n = len(adjacency_list)\n",
    "    A = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        A[i, adjacency_list[i]] = 1\n",
    "    return A\n",
    "A = read_adjacency_matrix(\"adjacency1.dat\")\n",
    "B = read_adjacency_matrix(\"adjacency2.dat\")\n",
    "C = read_adjacency_matrix(\"adjacency3.dat\")\n",
    "D = read_adjacency_matrix(\"adjacency4.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 1 : Comparación de soluciones con GMRes y PALU\n",
    "\n",
    "En esta sección se compararán las soluciones de PageRank obtenidas por medio de GMRes y PALU. Para esto, se considerarán los datasets de los archivos `adjacency1.dat`, `adjacency2.dat`, `adjacency3.dat` y `adjacency4.dat`, variaciones en el _damping factor_ $\\alpha$ y el número de iteraciones $k$ de GMRes.\n",
    "\n",
    "**1.** Construya el sistema lineal necesario para encontrar PageRank. Para ello desarrolle la función `build_linear_system`, que recibe una matriz de adyacencia $A$ y un _damping factor_ $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input:\n",
    "A - (n x n matrix) adjacency matrix\n",
    "alpha - (float) damping factor, takes values from 0 to 1\n",
    "Output: \n",
    "A_hat - (n x n matrix) matrix of linear system\n",
    "b_hat - (n vector) right hand side vector of linear system\n",
    "'''\n",
    "def build_linear_system(A, alpha):\n",
    "    #matriz P \n",
    "    P = np.zeros((len(A),len(A)))\n",
    "    P=A\n",
    "    v1=0\n",
    "    for x in P:\n",
    "        v2=0\n",
    "        s=sum(x)\n",
    "        for i in x:\n",
    "            if i==1:\n",
    "                P[v1][v2]=1/s\n",
    "            v2=v2+1\n",
    "        v1=v1+1\n",
    "    #matriz I\n",
    "    I=np.zeros((len(A),len(A)))\n",
    "    np.fill_diagonal(I,1)\n",
    "    #Matriz v\n",
    "    v=np.full((len(A), 1), 1/len(A))\n",
    "    #b_hat\n",
    "    b_hat=np.zeros((len(A),len(A)))\n",
    "    b_hat=(1-alpha)*v\n",
    "    #A_hat\n",
    "    A_hat=np.zeros((len(A),len(A)))\n",
    "    A_hat=I-(alpha*np.transpose(P))               \n",
    "    return A_hat, b_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Considere el error $e_k = \\|\\mathbf{x^{k}_{G}}-\\mathbf{x_{P}}\\|_2$ una métrica de error que compara $\\mathbf{x_{P}}$, la solución de PageRank obtenida por PALU, con $\\mathbf{x^{k}_{G}}$ la solución de PageRank obtenida con $k$ iteraciones de GMRes. Construya un gráfico que muestre $e_k$ versus $k$ y utilice un widget para seleccionar un dataset y variar el valor del _damping factor_ $\\alpha$. ¿Qué puede decir de la información mostrada en el gráfico? ¿Cómo afecta $\\alpha$ en los resultados obtenidos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###PALU\n",
    "def solve_triangular(A, b, upper=True):\n",
    "    n = b.shape[0]\n",
    "    x = np.zeros_like(b)\n",
    "    if upper==True:\n",
    "        #perform back-substitution\n",
    "        x[-1] = (1./A[-1,-1]) * b[-1]\n",
    "        for i in range(n-2, -1, -1):\n",
    "            x[i] = (1./A[i,i]) * (b[i] - np.sum(A[i,i+1:] * x[i+1:]))\n",
    "    else:\n",
    "        #perform forward-substitution\n",
    "        x[0] = (1./A[0,0]) * b[0]\n",
    "        for i in range(1,n):\n",
    "            x[i] = (1./A[i,i]) * (b[i] - np.sum(A[i,:i] * x[:i]))\n",
    "    return x\n",
    "\n",
    "def palu_decomp(A):\n",
    "    N,_ = A.shape\n",
    "    P = np.identity(N)\n",
    "    L = np.zeros((N,N))\n",
    "    U = np.copy(A)\n",
    "    #iterating through columns\n",
    "    for j in range(N-1):\n",
    "        #determine the new pivot\n",
    "        p_index = np.argmax(np.abs(U[j:,j]))\n",
    "        if p_index != 0:\n",
    "            row_perm(P, j, j+p_index)\n",
    "            row_perm(U, j, j+p_index)\n",
    "            row_perm(L, j, j+p_index)\n",
    "        #iterating through rows\n",
    "        for i in range(j+1,N):\n",
    "            L[i,j] = U[i,j]/U[j,j]\n",
    "            U[i] -= L[i,j]*U[j]\n",
    "    np.fill_diagonal(L,1)\n",
    "    return P,L,U\n",
    "def solve_palu(A, b):\n",
    "    P,L,U = palu_decomp(A)\n",
    "    #A.x = b -> P.A.x = P.b = b'\n",
    "    b = np.dot(P,b)\n",
    "    # L.c = b' with c = U.x\n",
    "    c = solve_triangular(L, b, upper=False)\n",
    "    x = solve_triangular(U, c)\n",
    "    x=(1/sum(x))*x\n",
    "    return x\n",
    "\n",
    "##GMres\n",
    "def GMRes(A, b, x0=np.array([0.0]), m=10, flag_display=False, threshold=1e-12):\n",
    "    todas=np.zeros((m,len(b)))\n",
    "    n = len(b)\n",
    "    if len(x0)==1:\n",
    "        x0=np.zeros(n)\n",
    "    r0 = b - np.dot(A, x0)\n",
    "    nr0=np.linalg.norm(r0)\n",
    "    out_res=np.array(nr0)\n",
    "    Q = np.zeros((n,n))\n",
    "    H = np.zeros((n,n))\n",
    "    Q[:,0] = r0 / nr0\n",
    "    flag_break=False\n",
    "    matris=0\n",
    "    for k in np.arange(np.min((m,n))):\n",
    "        y = np.dot(A, Q[:,k])\n",
    "        if flag_display:\n",
    "            print('||y||=',np.linalg.norm(y))\n",
    "        for j in np.arange(k+1):\n",
    "            H[j][k] = np.dot(Q[:,j], y)\n",
    "            if flag_display:\n",
    "                print('H[',j,'][',k,']=',H[j][k])\n",
    "            y = y - np.dot(H[j][k],Q[:,j])\n",
    "            if flag_display:\n",
    "                print('||y||=',np.linalg.norm(y))\n",
    "        # All but the last equation are treated equally. Why?\n",
    "        if k+1<n:\n",
    "            H[k+1][k] = np.linalg.norm(y)\n",
    "            if flag_display:\n",
    "                print('H[',k+1,'][',k,']=',H[k+1][k])\n",
    "            if (np.abs(H[k+1][k]) > 1e-16):\n",
    "                Q[:,k+1] = y/H[k+1][k]\n",
    "            else:\n",
    "                #print('flag_break has been activated')\n",
    "                flag_break=True\n",
    "            # Do you remember e_1? The canonical vector.\n",
    "            e1 = np.zeros((k+1)+1)        \n",
    "            e1[0]=1\n",
    "            H_tilde=H[0:(k+1)+1,0:k+1]\n",
    "        else:\n",
    "            H_tilde=H[0:k+1,0:k+1]\n",
    "        # Solving the 'SMALL' least square problem. \n",
    "        # This could be improved with Givens rotations!\n",
    "        ck = np.linalg.lstsq(H_tilde, nr0*e1)[0] \n",
    "        if k+1<n:\n",
    "            x = x0 + np.dot(Q[:,0:(k+1)], ck)\n",
    "        else:\n",
    "            x = x0 + np.dot(Q, ck)\n",
    "        # Why is 'norm_small' equal to 'norm_full'?\n",
    "        norm_small=np.linalg.norm(np.dot(H_tilde,ck)-nr0*e1)\n",
    "        out_res = np.append(out_res,norm_small)\n",
    "        if flag_display:\n",
    "            norm_full=np.linalg.norm(b-np.dot(A,x))\n",
    "            #print('..........||b-A\\,x_k||=',norm_full)\n",
    "            #print('..........||H_k\\,c_k-nr0*e1||',norm_small);\n",
    "        todas[matris]=x\n",
    "        matris=matris+1\n",
    "        #print(x)\n",
    "        if flag_break:\n",
    "            if flag_display: \n",
    "                print('EXIT: flag_break=True')\n",
    "            break\n",
    "        if norm_small<threshold:\n",
    "            if flag_display:\n",
    "                print('EXIT: norm_small<threshold')\n",
    "            break\n",
    "    return todas,out_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b15d57545504ee5a1bfc3809e7f2657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='data', max=4, min=1), FloatSlider(value=0.55, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.error(data, alpha, k)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def error(data,alpha,k):\n",
    "    errores=[]\n",
    "    if data==1:\n",
    "        Ma,Vb=build_linear_system(A,alpha)\n",
    "    elif data==2:\n",
    "        Ma,Vb=build_linear_system(B,alpha)\n",
    "    elif data==3:\n",
    "        Ma,Vb=build_linear_system(C,alpha)\n",
    "    else:\n",
    "        Ma,Vb=build_linear_system(D,alpha)\n",
    "    Px=solve_palu(Ma,Vb)   \n",
    "    Vb=np.transpose(Vb)\n",
    "    Gxk, _ = GMRes(Ma, Vb[0],m=k)\n",
    "    for x in Gxk:\n",
    "        con=0\n",
    "        Gx=np.zeros((len(x),1))\n",
    "        for i in x:\n",
    "            Gx[con]=i\n",
    "            con=con+1\n",
    "        err=np.linalg.norm(Gx-Px)\n",
    "        errores.append(err)\n",
    "    lista = range(1,len(errores)+1)\n",
    "    vx=list(lista)\n",
    "    plt.scatter(vx, errores)\n",
    "    plt.title(\"Plot k v/s error\")\n",
    "    plt.show()\n",
    "    return False\n",
    "\n",
    "interact(error,data=IntSlider(min=1,max=4,step=1,value=3),alpha=(0.1,1.0,0.01),k=IntSlider(min=1,max=100,step=1,value=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 2 : Tiempo de Ejecución\n",
    "\n",
    "En esta sección se compararán los tiempos de ejecución de GMRes y PALU necesarios para resolver los sistemas de ecuaciones de PageRank. Para esto, se considerarán los datasets de los archivos `adjacency1.dat`, `adjacency2.dat`, `adjacency3.dat` y `adjacency4.dat`, variaciones en el _damping factor_ $\\alpha$ y el número de iteraciones $k$ de GMRes.\n",
    "\n",
    "**1.** Analice efecto de variar _damping factor_ $\\alpha$ para encontrar las 10 primeras páginas entregadas por PageRank. Para ello utilice la función `get_damping_ranking` definida a continuación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cesar\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([2.40000000e+01, 1.25840274e-02]),\n",
       " array([3.70000000e+01, 1.19785908e-02]),\n",
       " array([7.40000000e+01, 1.19208987e-02]),\n",
       " array([6.00000000e+01, 1.16476491e-02]),\n",
       " array([5.00000000e+01, 1.15140201e-02]),\n",
       " array([9.60000000e+01, 1.15052893e-02]),\n",
       " array([3.40000000e+01, 1.13483387e-02]),\n",
       " array([1.        , 0.01130623]),\n",
       " array([6.80000000e+01, 1.13008833e-02]),\n",
       " array([8.90000000e+01, 1.12636799e-02])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top(lista):\n",
    "    list_top=[]\n",
    "    n = lista\n",
    "    idx = n.argsort()[-1]\n",
    "    list_top.append(np.array((idx+1, n[idx])))\n",
    "    idx2 = n.argsort()[-2]\n",
    "    list_top.append(np.array((idx2+1, n[idx2])))\n",
    "    idx3 = n.argsort()[-3]\n",
    "    list_top.append(np.array((idx3+1, n[idx3])))\n",
    "    idx4 = n.argsort()[-4]\n",
    "    list_top.append(np.array((idx4+1, n[idx4])))\n",
    "    idx5 = n.argsort()[-5]\n",
    "    list_top.append(np.array((idx5+1, n[idx5])))\n",
    "    idx6 = n.argsort()[-6]\n",
    "    list_top.append(np.array((idx6+1, n[idx6])))\n",
    "    idx7 = n.argsort()[-7]\n",
    "    list_top.append(np.array((idx7+1, n[idx7])))\n",
    "    idx8 = n.argsort()[-8]\n",
    "    list_top.append(np.array((idx8+1, n[idx8])))\n",
    "    idx9 = n.argsort()[-9]\n",
    "    list_top.append(np.array((idx9+1, n[idx9])))\n",
    "    idx10 = n.argsort()[-10]\n",
    "    list_top.append(np.array((idx10+1, n[idx10])))    \n",
    "    return list_top\n",
    "        \n",
    "'''\n",
    "Input:\n",
    "A - (n x n matrix) adjacency matrix\n",
    "alpha - (float) damping factor, takes values from 0 to 1\n",
    "k - number of iterations of GMRes until return a solution, use only if method is 'GMRes'\n",
    "method - string that indicates the method used to solve the linear system. Take values 'PALU' or 'GMRes'\n",
    "Output: \n",
    "ranking - list with 10 pages of ranking sorted by largest probability\n",
    "'''\n",
    "def get_damping_ranking(A, alpha, k, method='GMRes'):\n",
    "    Ma,Vb=build_linear_system(A, alpha)\n",
    "    Px=solve_palu(Ma,Vb)   \n",
    "    Vb=np.transpose(Vb)       \n",
    "    if \"GMRes\"== method:\n",
    "        Gxk, _ = GMRes(Ma, Vb[0],m=k)\n",
    "        Gx=np.zeros((len(Ma),1))\n",
    "        Gx=Gxk[len(Gxk)-1]\n",
    "        ranking=top(Gx)\n",
    "        \n",
    "    else:\n",
    "        Px=np.transpose(Px)[0]\n",
    "        ranking=top(Px)\n",
    "    return ranking\n",
    "\n",
    "\n",
    "get_damping_ranking(A,0.5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Construya un gráfico que muestre el tiempo de ejecución para determinar el ranking versus el factor de amortiguamiento $\\alpha$. En el mismo gráfico debe mostrar los dos métodos utilizados (GMRes y PALU). Además, utilice un widget que permita seleccionar uno de los cuatro datasets mencionados y el número $k$ de iteraciones de GMRes. ¿Qué puede decir respecto de los resultados obtenidos en cada método al variar el valor de $\\alpha$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f199af7b94f64c77b36b1fa61cc29513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='data', max=4, min=1), IntSlider(value=10, description='k…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.tiempo(data, k, metodo)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#metodo=1 GMRes\n",
    "#metodo=2 PALU\n",
    "\n",
    "def tiempo (data,k,metodo):\n",
    "    alpha=0\n",
    "    lista_1=[]\n",
    "    lista_2=[]\n",
    "    if data==1:\n",
    "        dA = read_adjacency_matrix(\"adjacency1.dat\")\n",
    "    elif data==2:\n",
    "        dA = read_adjacency_matrix(\"adjacency2.dat\")\n",
    "    elif data==3:\n",
    "        dA = read_adjacency_matrix(\"adjacency3.dat\")\n",
    "    else:\n",
    "        dA = read_adjacency_matrix(\"adjacency4.dat\")\n",
    "    for i in range(1,20):        \n",
    "        tiempo_inicial = time() \n",
    "        if metodo==1:\n",
    "            get_damping_ranking(dA, alpha, k, method='GMRes')\n",
    "        else:\n",
    "            get_damping_ranking(dA, alpha, k, method='PALU')\n",
    "\n",
    "        lista_1.append(alpha)\n",
    "        alpha=alpha+0.05\n",
    "        tiempo_final = time() \n",
    "        tiempo_ejecucion = tiempo_final - tiempo_inicial\n",
    "        lista_2.append(tiempo_ejecucion)\n",
    "    plt.scatter(lista_2, lista_1)\n",
    "    plt.title(\"alpha vs tiempo\")\n",
    "    plt.show()\n",
    "    return 0\n",
    "\n",
    "#tiempo(4,A,B,C,D,10,1)\n",
    "\n",
    "interact(tiempo,data=IntSlider(min=1,max=4,step=1,value=3),k=IntSlider(min=1,max=100,step=1,value=10),metodo=(1,2,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección 3 : Análisis de iteraciones de GMRes\n",
    "\n",
    "En esta sección debe analizar las soluciones obtenidas por GMRes en cada iteración, utilizando los datasets `web-NotreDame` y `web-Stanford`. Se recomienda modificar el código de GMRes de los Jupyter Notebook del curso, aunque no es obligatorio. **Importante:** Debido al tamaño de estos datasets, no se debe intentar cargar toda la matriz de adyacencia en memoria en formato denso\n",
    "\n",
    "Considere la relación error $e_{k}$ versus iteración $k$, donde el error puede ser definido de la siguiente manera:\n",
    "\n",
    "$$\n",
    "e_{k} = \\| \\mathbf{x}_{k}-\\mathbf{x}_{k-1} \\|_2\n",
    "$$\n",
    "\n",
    "   Donde $\\mathbf{x}_k$ es la solución de GMRes obtenida en la iteración $k$-ésima, con $k$ que **puede tomar valores** en el rango $[1, 2, \\ldots, m]$. y $m$ el número de páginas del dataset. \n",
    "   \n",
    "**1.** Utilice GMRes de manera conveniente para graficar el error $e_k$ versus $k$, utilizando un widget para variar el _damping factor_ $\\alpha$ y seleccionar uno de los dos datasets requeridos. ¿Qué puede decir del error a medida que $k$ aumenta? ¿En qué afecta el valor de $\\alpha$?\n",
    "\n",
    "**Recomendación:** no intente cargar toda la matriz $\\widehat{A}$ en memoria. En lugar de eso, considere que debido a que $\\widehat{A}$ es _sparse_, la matriz $P$ también lo es y evite el cálculo de productos exteriores explícitamente. Se recomienda revisar el módulo `sparse` de `scipy` . Puede recurrir a modificaciones de GMRes para desarrollar esta pregunta. Utilice un valor máximo de $k$ razonable, pero no muy pequeño. No debe llegar necesariamente a $k = m$. Justifique su elección apropiadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.74908024 1.90142861 1.46398788 ... 0.85508204 0.05083825 0.21578285]\n",
      " [0.06285837 1.27282082 0.62871196 ... 1.79422052 1.77417285 1.55975109]\n",
      " [1.28406329 0.16827993 0.32325743 ... 0.43164205 1.24578095 0.17069493]\n",
      " ...\n",
      " [1.18823974 1.01531142 0.41756942 ... 1.58206745 1.85359295 0.60241292]\n",
      " [0.16050398 1.97771288 1.15246621 ... 1.51226309 0.51651106 0.99064441]\n",
      " [0.58080629 1.43377084 1.99391229 ... 0.83614396 0.85734251 1.8588971 ]]\n",
      "Size of full matrix with zeros: 7.63 MB\n",
      "  (0, 0)\t0.749080237694725\n",
      "  (0, 1)\t1.9014286128198323\n",
      "  (0, 2)\t1.4639878836228102\n",
      "  (0, 3)\t1.1973169683940732\n",
      "  (0, 4)\t0.31203728088487304\n",
      "  (0, 5)\t0.3119890406724053\n",
      "  (0, 6)\t0.11616722433639892\n",
      "  (0, 7)\t1.7323522915498704\n",
      "  (0, 8)\t1.2022300234864176\n",
      "  (0, 9)\t1.416145155592091\n",
      "  (0, 10)\t0.041168988591604894\n",
      "  (0, 11)\t1.9398197043239886\n",
      "  (0, 12)\t1.6648852816008435\n",
      "  (0, 13)\t0.4246782213565523\n",
      "  (0, 14)\t0.36364993441420124\n",
      "  (0, 15)\t0.36680901970686763\n",
      "  (0, 16)\t0.6084844859190754\n",
      "  (0, 17)\t1.0495128632644757\n",
      "  (0, 18)\t0.8638900372842315\n",
      "  (0, 19)\t0.5824582803960838\n",
      "  (0, 20)\t1.223705789444759\n",
      "  (0, 21)\t0.27898772130408367\n",
      "  (0, 22)\t0.5842892970704363\n",
      "  (0, 23)\t0.7327236865873834\n",
      "  (0, 24)\t0.9121399684340719\n",
      "  :\t:\n",
      "  (9999, 75)\t0.875558371859118\n",
      "  (9999, 76)\t1.5335169251516423\n",
      "  (9999, 77)\t1.592533417379028\n",
      "  (9999, 78)\t0.20435340496668886\n",
      "  (9999, 79)\t0.7539393016862379\n",
      "  (9999, 80)\t0.781887012209197\n",
      "  (9999, 81)\t0.2672941174586747\n",
      "  (9999, 82)\t1.8337557661480992\n",
      "  (9999, 83)\t0.16910250138033844\n",
      "  (9999, 84)\t0.25345700091242285\n",
      "  (9999, 85)\t1.1355324516004655\n",
      "  (9999, 86)\t0.4776544224377881\n",
      "  (9999, 87)\t1.5574084283834124\n",
      "  (9999, 88)\t1.2940159754333527\n",
      "  (9999, 89)\t1.5965601310490753\n",
      "  (9999, 90)\t0.987437586453159\n",
      "  (9999, 91)\t1.8634089022751805\n",
      "  (9999, 92)\t0.03395008575016223\n",
      "  (9999, 93)\t0.4654139589027648\n",
      "  (9999, 94)\t1.1970293598543735\n",
      "  (9999, 95)\t1.7761616664234174\n",
      "  (9999, 96)\t0.8746375162772508\n",
      "  (9999, 97)\t0.8361439640677619\n",
      "  (9999, 98)\t0.8573425133717938\n",
      "  (9999, 99)\t1.8588970957010307\n",
      "Size of sparse csr_matrix: 0.95 MB\n",
      "--------------------------------\n",
      "[[0.74908024 1.90142861 1.46398788 ... 0.85508204 0.05083825 0.21578285]\n",
      " [0.06285837 1.27282082 0.62871196 ... 1.79422052 1.77417285 1.55975109]\n",
      " [1.28406329 0.16827993 0.32325743 ... 0.43164205 1.24578095 0.17069493]\n",
      " ...\n",
      " [1.18823974 1.01531142 0.41756942 ... 1.58206745 1.85359295 0.60241292]\n",
      " [0.16050398 1.97771288 1.15246621 ... 1.51226309 0.51651106 0.99064441]\n",
      " [0.58080629 1.43377084 1.99391229 ... 0.83614396 0.85734251 1.8588971 ]]\n"
     ]
    }
   ],
   "source": [
    "# import sparse module from SciPy package \n",
    "from scipy import sparse\n",
    "# import uniform module to create random numbers\n",
    "from scipy.stats import uniform\n",
    "\n",
    "np.random.seed(seed=42)\n",
    "data = uniform.rvs(size=1000000, loc = 0, scale=2)\n",
    "data = np.reshape(data, (10000, 100))\n",
    "\n",
    "data_size = data.nbytes/(1024**2)\n",
    "print(data)\n",
    "print('Size of full matrix with zeros: '+ '%3.2f' %data_size + ' MB')\n",
    "\n",
    "data_csr = sparse.csr_matrix(data)\n",
    "data_csr_size = data_csr.data.size/(1024**2)\n",
    "print(data_csr)\n",
    "print('Size of sparse csr_matrix: '+ '%3.2f' %data_csr_size + ' MB')\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "print(data_csr.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias\n",
    "\n",
    "* Jupyter_Notebook_04_Metodos_Directos , del material de clases\n",
    "\n",
    "* https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.gmres.html\n",
    "\n",
    "* https://github.com/tclaudioe/Scientific-Computing/blob/master/SC1/10_GMRes.ipynb\n",
    "\n",
    "* https://machinelearningmastery.com/sparse-matrices-for-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
